defaults:
  - dataset: cifar100
  - classifier: preresnet
  - density_model: sngan
  - logger: local
  - loss: ts_fwd_cross_ent

augmentation:
  random_apply:
    _target_: torchvision.transforms.RandomApply
    p: 1.
  #geometric
  rotation:
    _target_: torchvision.transforms.RandomRotation
    degrees: 90
  crop:
    _target_: torchvision.transforms.RandomCrop
    size: ${dataset.input_size}
    padding: 4
  horizontal_flip:
    _target_: torchvision.transforms.RandomHorizontalFlip
  vertical_flip:
    _target_: torchvision.transforms.RandomVerticalFlip
  perspective:
    _target_: torchvision.transforms.RandomPerspective
    distortion_scale: 0.5
    p: 0.5
  #colorspace
  grayscale:
    _target_: torchvision.transforms.RandomGrayscale
    p: 0.1
  colorjitter:
    _target_: torchvision.transforms.ColorJitter
    brightness: 0.2
    contrast: 0.2
    saturation: 0.2
    hue: 0.2
  gaussian_blur:
    _target_: torchvision.transforms.GaussianBlur
    kernel_size: 3
    sigma:
      - 0.1
      - 2.0
  transforms_list:
    - crop
    - horizontal_flip
  normalization: unitcube

teacher:
  name: ${classifier.name}
  depth: ${classifier.depth}
  num_components: 1
  use_ckpts: True
  ckpt_init:
    type: null
    loc_param: 0.0
  shuffle_ckpts: False
  ckpt_dir:
            "test/${teacher.name}${teacher.depth}_${dataset.name}_${augmentation.normalization}"

trainer:
  num_epochs: 300
  eval_period: 10
  eval_dataset: test
  optimizer:
    _target_: torch.optim.SGD
    lr: 5e-2
    weight_decay: 1e-4
    momentum: 0.9
    nesterov: True
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: ${trainer.num_epochs}
    eta_min: 1e-6
  distill_teacher: True
  synth_aug:
    ratio: 0.
  freeze_bn: False

dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 128
  shuffle: True

distill_loader:
  _target_: gnosis.distillation.dataloaders.DistillLoader
  splits:
    - 0
  temp: 4.0
  mixup_alpha: 0. # if alpha > 0, the mixup training is active
  mixup_portion: 1.
  batch_size: ${dataloader.batch_size}
  shuffle: True
  drop_last: False
  synth_ratio: 0.0

seed: ${trial_id}
trial_id: 0
project_name: gnosis
version: v0.1.0

# Directories for loading and storing data
dataset_dir: data/datasets
project_dir: cwd
data_dir: data/experiments/image_classification
exp_name: test/${classifier.name}${classifier.depth}_${dataset.name}_${augmentation.normalization}
job_name: null
timestamp: ${now:%Y-%m-%d_%H-%M-%S}
log_dir: ${data_dir}/${exp_name}

# Checkpointing
ckpt_store: local
s3_bucket: null

hydra:
  run:
    dir: ./${log_dir}
  sweep:
    dir: ./${log_dir}
    subdir: .
